{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import clickhouse_connect\n","import pandas as pd\n","import requests\n","import yaml\n","import os\n","\n","\n","VANTAGE_TOKEN = os.getenv(\"VANTAGE_TOKEN\")\n","CLIKHOUSE_HOST = os.getenv(\"CLICKHOUSE_HOST\")\n","CLICKHOUSE_USER = os.getenv(\"CLICKHOUSE_USER\")\n","CLICKHOUSE_PASSWORD = os.getenv(\"CLICKHOUSE_PASSWORD\")\n","\n","VANTAGE_BASE_URL = \"https://api.vantage.sh/v2\"\n","\n","VANTAGE_HEADERS = {\n","    \"accept\": \"application/json\",\n","    \"authorization\": f\"Bearer {VANTAGE_TOKEN}\"\n","}\n","\n","client = clickhouse_connect.get_client(\n","    host=CLIKHOUSE_HOST,\n","    user=CLICKHOUSE_USER,\n","    password=CLICKHOUSE_PASSWORD,\n","    secure=True\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# unique runner types for last 7 days:\n","\n","query = \"select distinct(labels) from workflow_job where completed_at > DATE('2024-09-10')\"\n","\n","runner_types = client.query(query).result_set\n","\n","# make a dataframe with all unique runner types, knowing that every entry is a list of strings, to flatten the list\n","runner_types_set = set()\n","for runner_list in runner_types:\n","    for runner in runner_list:\n","        runner_types_set.update(runner)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# load runner map from scale-config.yml\n","yaml_url = 'https://raw.githubusercontent.com/pytorch/test-infra/main/.github/scale-config.yml'\n","yaml_file = requests.get(yaml_url)\n","\n","# read the yaml file from the response\n","scale_config = yaml.safe_load(yaml_file.text)\n","runner_map = scale_config['runner_types']\n","\n","# load second yaml from pytorch/pytorch -> .github/lf-scale-config.yml\n","yaml_url = 'https://raw.githubusercontent.com/pytorch/pytorch/main/.github/lf-scale-config.yml'\n","yaml_file = requests.get(yaml_url)\n","lf_scale_config = yaml.safe_load(yaml_file.text)\n","runner_map.update(lf_scale_config['runner_types'])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["vantage_product_id_cache = {}\n","def get_vantage_product_id(instance_type):\n","    if instance_type is None:\n","        return None\n","    \n","    if instance_type in vantage_product_id_cache:\n","        return vantage_product_id_cache[instance_type]\n","\n","    response = requests.get(f\"{VANTAGE_BASE_URL}/products?provider_id=aws&service_id=aws-ec2&name={instance_type}\", headers=VANTAGE_HEADERS)\n","    json_response = response.json()\n","    if not 'products' in json_response:\n","        print(f\"Error - couldn't find products in json: {json_response}\")\n","        return None\n","    for product in json_response['products']:\n","        if product['name'] == instance_type:\n","            vantage_product_id_cache[instance_type] = product['id']\n","            return product['id']\n","    print(f\"Error - couldn't find product with name {instance_type}\")\n","    vantage_product_id_cache[instance_type] = None\n","    return None"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["price_cache = {}\n","def get_vantage_price_ondemand(vantage_id, region='us-east-1', platform='linux'):\n","    today = pd.Timestamp.today().date()\n","    if vantage_id is None:\n","        return None\n","    price_key = f\"{vantage_id}-{region.replace('-','_')}-on_demand-{platform}\"\n","    if f\"{today}-{price_key}\" in price_cache:\n","        return price_cache[f\"{today}-{price_key}\"]\n","    response = requests.get(f\"{VANTAGE_BASE_URL}/products/{vantage_id}/prices\", headers=VANTAGE_HEADERS)\n","    json_response = response.json()\n","    if not 'prices' in json_response:\n","        print(f\"Error - couldn't find prices in json: {json_response}\")\n","        return None\n","    for price in json_response['prices']:\n","        if price['id'] == price_key:\n","            price_cache[f\"{today}-{price_key}\"] = price['amount']\n","            return price['amount']\n","        # if price['unit'] == 'hour' and price['details']['lifecycle'] == 'on_demand' and price['region'] == region and price['details']['platform'] == platform:\n","        #     return price['amount']\n","    print(f\"Error - couldn't find price with unit hour in json: {json_response}\")\n","    return None"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# now create a dataframe with runner types and instance types\n","runner_types_df = pd.DataFrame(runner_types_set, columns=['runner_type'])\n","runner_types_df['instance_type'] = runner_types_df['runner_type'].map(lambda s: runner_map[s]['instance_type'] if s in runner_map else None)\n","runner_types_df['os']= runner_types_df['runner_type'].map(lambda s: runner_map[s]['os'] if s in runner_map else None)  \n","runner_types_df['vantage_product_id'] = runner_types_df['instance_type'].map(get_vantage_product_id)\n","runner_types_df['vantage_price'] = runner_types_df['vantage_product_id'].map(get_vantage_price_ondemand)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(f\"we found {runner_types_df[runner_types_df['vantage_price'].notnull()].shape[0]}/{runner_types_df.shape[0] } prices\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# show only those that don't have None in the vantage_price column, dort by instance type\n","runner_types_df[runner_types_df['vantage_price'].notnull()].sort_values(by='vantage_price')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# print those without a price\n","runner_types_df[runner_types_df['vantage_price'].isnull()]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# now use clickhouse to get all entries in the last 7 days for the table workflow_job\n","DAYS=7\n","today = pd.Timestamp.today().date()\n","seven_days_ago = today - pd.Timedelta(days=DAYS)\n","seven_days_ago_str = seven_days_ago.strftime('%Y-%m-%d')\n","\n","query = f\"select * from materialized_views.workflow_job_by_started_at where started_at > DATE('{seven_days_ago_str}')\"\n","\n","workflow_jobs = client.query(query).result_set"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# also get the columns of the table\n","column_names = client.query(\"select * from workflow_job limit 1\").column_names\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["workflow_jobs_df = pd.DataFrame(workflow_jobs, columns=column_names)\n","print(f\"Found {workflow_jobs_df.shape[0]} entries in the last {DAYS} days\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# remove the item 'self-hosted' from the list of runner types\n","workflow_jobs_df['labels'] = workflow_jobs_df['labels'].map(lambda l: [x for x in l if x != 'self-hosted'])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# drop rows where labels is empty\n","workflow_jobs_df = workflow_jobs_df[workflow_jobs_df['labels'].map(len) > 0]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# add a column 'group' and 'repo' which is the first and second element of the dynamoKey split by '/', and a column branch, which is the first element of the head_branch column split by '/'\n","workflow_jobs_df['group'] = workflow_jobs_df['dynamoKey'].map(lambda s: s.split('/')[0])\n","workflow_jobs_df['repo'] = workflow_jobs_df['dynamoKey'].map(lambda s: s.split('/')[1])\n","workflow_jobs_df['branch'] = workflow_jobs_df['head_branch'].map(lambda s: s.split('/')[0])\n","# add a column that combines the previous 3:\n","workflow_jobs_df['group_repo_branch'] = workflow_jobs_df['group'] + '/' + workflow_jobs_df['repo'] + '/' + workflow_jobs_df['branch']\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# extend the df with runner_types_df, joining on runner_types_df.runner_type == workflow_jobs_df.labels[0]\n","workflow_jobs_df = workflow_jobs_df.merge(runner_types_df, left_on=workflow_jobs_df['labels'].map(lambda l: l[0]), right_on='runner_type', how='left')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# now add a column that subtracts the created_at from the completed_at column and gives a duration in hours\n","workflow_jobs_df['duration'] = (workflow_jobs_df['completed_at'] - workflow_jobs_df['started_at']).dt.total_seconds() / 3600"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# now we can calculate the cost of each job\n","workflow_jobs_df['cost'] = workflow_jobs_df['duration'] * workflow_jobs_df['vantage_price']"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# get everything where runner_type starts with lf\n","workflow_jobs_df_lf = workflow_jobs_df[workflow_jobs_df['runner_type'].map(lambda s: s.startswith('lf'))]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["workflow_jobs_df_lf['cost'].sum()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["workflow_jobs_df['duration'].sum()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# count how many have a price and how many don't\n","with_count = workflow_jobs_df['vantage_price'].notnull().value_counts()\n","print(f\"we have {with_count[True]} jobs with a price and {with_count[False]} without\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# count unique head_sha\n","workflow_jobs_df['run_id'].nunique()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# get all where run_id is 10910999394\n","# workflow_jobs_df[workflow_jobs_df['run_id'] == 10910999394]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# now make a sum by workflow name, plot in a table, sorted by cost, rounded to 2 decimals and with a $ sign, only keeping those over 100\n","workflow_jobs_df.groupby('workflow_name')['cost'].sum().reset_index().sort_values(by='cost', ascending=False).round(2).query('cost > 100').style.format({'cost': '${:,.2f}'})"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# group by runner_type\n","workflow_jobs_df.groupby('runner_type')['cost'].sum().reset_index().sort_values(by='cost', ascending=False).round(2).query('cost > 100').style.format({'cost': '${:,.2f}'})"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# group by name\n","workflow_jobs_df.groupby('name')['cost'].sum().reset_index().sort_values(by='cost', ascending=False).round(2).query('cost > 2000').style.format({'cost': '${:,.2f}'})"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# group by group_repo_branch\n","workflow_jobs_df.groupby('group_repo_branch')['cost'].sum().reset_index().sort_values(by='cost', ascending=False).round(2).query('cost > 500').style.format({'cost': '${:,.2f}'})"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# sort by longest running jobs\n","workflow_jobs_df.sort_values(by='duration', ascending=False).head(10)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# unique runner types without a price\n","workflow_jobs_df[workflow_jobs_df['instance_type'].isnull()]['labels'].map(lambda l: l[0]).unique()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# group by runner_type\n","workflow_jobs_df.groupby(['runner_type','instance_type'])['duration'].sum().reset_index().sort_values(by='duration', ascending=False).round(2).style.format({'duration': '{:,.2f}h'})"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["workflow_jobs_df_lf.duration.sum()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":2}
