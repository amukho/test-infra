# Week of 2025-05-05 to 2025-05-12 (25)

### GHFirst (9)

- [Revert "[dynamo] Avoid running `torch.nn.Module.__call__` twice under `torch.compile(mod)` (#152740)"](https://github.com/pytorch/pytorch/commit/d36261d2e65f1fc2e4056cd9b4b7fd4d0a80e217)
  - Discuss with the author to revert and reland this ([comment](https://github.com/pytorch/pytorch/pull/152740#issuecomment-2863779028))
- [Revert "[dynamo] Support `delattr` on result of `torch.compile(module)` (#152741)"](https://github.com/pytorch/pytorch/commit/34d424d8136c6a7807daee0336e94d27fbce8ed4)
  - Discuss with the author to revert and reland this ([comment](https://github.com/pytorch/pytorch/pull/152740#issuecomment-2863779028))
- [Revert "Add runtime asserts to AOTI (#152125)"](https://github.com/pytorch/pytorch/commit/05326b7e496799bfefdefcfd69f3714a1399673f)
  - Diff reverted internally ([comment](https://github.com/pytorch/pytorch/pull/152125#issuecomment-2863554139))
- [Revert "[aot][ca] save bw_module in AOTAutogradCache (#151860)"](https://github.com/pytorch/pytorch/commit/a28dcdba2c712b91b83ea8ba2c581b746e224f38)
  - Chatting with @xmfan and decide to revert and reland this instead ([comment](https://github.com/pytorch/pytorch/pull/151860#issuecomment-2856709646))
- [Revert "[ca] mark scalar int sizes as dynamic via tensor wrapping (#151731)"](https://github.com/pytorch/pytorch/commit/f6db749e601ed0f2305783204795fd525214b217)
  - Chatting with @xmfan and decide to revert and reland this instead ([comment](https://github.com/pytorch/pytorch/pull/151860#issuecomment-2856709646))
- [Revert "[ca] hide unused scalar int sizes from dynamo (#151962)"](https://github.com/pytorch/pytorch/commit/8f208dc75a01e5415133eca78a497fc2603173b6)
  - Chatting with @xmfan and decide to revert and reland this instead ([comment](https://github.com/pytorch/pytorch/pull/151860#issuecomment-2856709646))
- [Revert "[dynamo][ca] support dynamic annotations on tensors in ListVariables/TupleVariables (#152119)"](https://github.com/pytorch/pytorch/commit/64bbf58fb4a2077b48fe8b42b8ecb514d56fd7d4)
  - Chatting with @xmfan and decide to revert and reland this instead ([comment](https://github.com/pytorch/pytorch/pull/151860#issuecomment-2856709646))
- [Revert "[c10d] Fix extra CUDA context created by barrier (#149144)"](https://github.com/pytorch/pytorch/commit/cc954848d4ac4071371da3927157a87f969b7ef9)
  - Internal failure looks legit ([comment](https://github.com/pytorch/pytorch/pull/149144#issuecomment-2852564660))
- [Revert "Log aot and idx waitcounters. (#152444)"](https://github.com/pytorch/pytorch/commit/172a7c942edd4394f81fd0e889f10822af916b9e)
  - needs a fix ([comment](https://github.com/pytorch/pytorch/pull/152444#issuecomment-2851905261))

### Ignored Signal (4)

- [Revert "[CI] Add opt-in h100 tests (#153170)"](https://github.com/pytorch/pytorch/commit/34196301d58e14d9d97a1039b9b0d26de86b9bcb)
  - workflow doesnt have right concurrency group? ([comment](https://github.com/pytorch/pytorch/pull/153170#issuecomment-2864951319))
- [Revert "[BE]: Add PEP621 project section to pyproject.toml (#153055)"](https://github.com/pytorch/pytorch/commit/0203f89cc1937e6e97f4533b1a45bdc6c233b3fc)
  - And failures seems related to this change, but I don't know how, see for example https://hud.pytorch.org/hud/pytorch/pytorch/7cb5c751c3f76129c95aec479647679fbba4e7ba/1?per_page=50&name_filter=macos&mergeEphemeralLF=true ([comment](https://github.com/pytorch/pytorch/pull/153055#issuecomment-2864664725))
- [Revert "[dynamo] Recursively realize the stack_values (#152853)"](https://github.com/pytorch/pytorch/commit/fcd5e491382ebff38c11bf9eee094d4ce8d19107)
  - Looks like it broke inductor tests ([comment](https://github.com/pytorch/pytorch/pull/152853#issuecomment-2854897485))
- [Revert "[Inductor] FX backend via Wrapper IR (#146942)"](https://github.com/pytorch/pytorch/commit/99dac7005f84ced917f8f23c4f5762532eb19446)
  - Looks like it indeed breaks lint, see https://hud.pytorch.org/hud/pytorch/pytorch/a7691140a0fed33a838dda11e28ff7da393d9180/1?per_page=50&name_filter=lint&mergeEphemeralLF=true ([comment](https://github.com/pytorch/pytorch/pull/146942#issuecomment-2852192778))

### Not through pytorchbot (1)

- [Revert "Cleanup VS 2019 refs in pytorch (#145863)" (#152613)](https://github.com/pytorch/pytorch/commit/e4f22822cbe8b16d6c435a4f34fbfd62f0e23d91)

### No Signal (11)

- [Revert "refine fp32 precision api (#125888)"](https://github.com/pytorch/pytorch/commit/fdc387ec7c9ea0eb32bbbb149e0fccf5a7d05eea)
  - Sorry for reverting your change but it seems to cause some failures on ROCm ([comment](https://github.com/pytorch/pytorch/pull/125888#issuecomment-2869274791))
- [Revert "`has_triton`: Use the device interface for detecting Triton availability (#139171)"](https://github.com/pytorch/pytorch/commit/01bb249978a023d3531b6461956de0f188a7b080)
  - Performance regression for huggingface ([comment](https://github.com/pytorch/pytorch/pull/139171#issuecomment-2868939790))
- [Revert "Fix fake tensor caching when output has unbacked (#153034)"](https://github.com/pytorch/pytorch/commit/e6dccb036e185cd05c3859126bffd9644ba768b5)
  - Broke pr_time_benchmarks, see https://hud.pytorch.org/hud/pytorch/pytorch/d07fbd41e3589fc9377865a95960b211ec899b90/1?per_page=50&name_filter=pr_time_be&mergeEphemeralLF=true ([comment](https://github.com/pytorch/pytorch/pull/153034#issuecomment-2868100487))
- [Revert "[inductor][dynamo] Include operator name in size/stride/alignment assertion (#152353)"](https://github.com/pytorch/pytorch/commit/7b806a8cb1eb927e4db468e4c19b192a85a0d5d9)
  - Sorry for reverting your change but it seems to fail an inductor test in trunk ([comment](https://github.com/pytorch/pytorch/pull/152353#issuecomment-2863657185))
- [Revert "[CI] Use cmake from pip instead of conda in CI docker images (#152537)"](https://github.com/pytorch/pytorch/commit/a7ea115494ab7fa5d8fbd260f295a737b946e00b)
  - Sorry to revert this PR, but it broke doc builds, see https://hud.pytorch.org/hud/pytorch/pytorch/4976b1a3a823ee175ec51ed5915e5070ff934a12/1?per_page=50&name_filter=docs&mergeEphemeralLF=true ([comment](https://github.com/pytorch/pytorch/pull/152537#issuecomment-2863337268))
- [Revert "[BE] Update numba versions (#152557)"](https://github.com/pytorch/pytorch/commit/61dd2a0cc389208de2a152531fb916d020bdb4a4)
  - This time it breaks torchbench tests, see https://hud.pytorch.org/hud/pytorch/pytorch/9c114934f7b20d6cd26d8c03b4a6fcd7c4a4665e/1?per_page=50&name_filter=nductor%20%2F%20cuda12.6-py3.10-gcc9-sm86%20%2F%20test%20(inductor_torc&mergeEphemeralLF=true ([comment](https://github.com/pytorch/pytorch/pull/152557#issuecomment-2858945427))
- [Revert "cleanup, refactor and add missing  self._dde_suppressed checks (#152657)"](https://github.com/pytorch/pytorch/commit/0e2b94825600bc36e2d61b8423a5bd5f4c8c9201)
  - Sorry for reverting your change but it seems to cause a test to fail in trunk ([comment](https://github.com/pytorch/pytorch/pull/152657#issuecomment-2853442594))
- [Revert "Make device check error message more descriptive (#150750)"](https://github.com/pytorch/pytorch/commit/451d652873c1e56bdff232d212c475b2c6ff4346)
  - Sorry for reverting your change but it seems to cause a test to fail in trunk ([comment](https://github.com/pytorch/pytorch/pull/150750#issuecomment-2853438985))
- [Revert "[CI] Use cmake from pip instead of conda in CI docker images (#152537)"](https://github.com/pytorch/pytorch/commit/d197228d4330ebe10d2d8e4363086bddbd97b2cf)
  - We need signals from inductor, cmake version from pip is too old? ([comment](https://github.com/pytorch/pytorch/pull/152537#issuecomment-2852820175))
- [Revert "Add infra to run CPython tests under Dynamo (#150787)"](https://github.com/pytorch/pytorch/commit/103fe856e1fe408be0c738ca6fb734592ad5014d)
  - Sorry for reverting your change but a failed test is showing up in trunk ([comment](https://github.com/pytorch/pytorch/pull/150787#issuecomment-2852818113))
- [Revert "[float16]: Fast path for torch.dot with float16/bfloat16 (#152799)"](https://github.com/pytorch/pytorch/commit/fdadda21b6ca88eede54930ae58278cd1f67e944)
  - This broke C10_MOBILE builds, not sure why it was not surfaced on pull, see https://hud.pytorch.org/hud/pytorch/pytorch/a766c1d117bbdf348d1a9d02a514651b3e05b1e4/1?per_page=50&name_filter=lightweight&mergeEphemeralLF=true ([comment](https://github.com/pytorch/pytorch/pull/152799#issuecomment-2852084433))
