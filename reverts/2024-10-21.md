# Week of 2024-10-21 to 2024-10-28 (16)

### GHFirst (5)

- [Revert "[c10d][Partial-Graph Overlap] Support calling .wait_tensor() within compiled region on output tensor of eager `async_op=True` collective (#137763)"](https://github.com/pytorch/pytorch/commit/e7f1e306dfd1675e4fbe126ca01a9bbbeb49ecc5)
  - this change is breaking our prod training pipeline (verified with bisect) by increasing memory consumption 4x and causing OOM ([comment](https://github.com/pytorch/pytorch/pull/137763#issuecomment-2435962833))
- [Revert "Make Context to be Device-agnostic Step by Step (2/N) (#136526)"](https://github.com/pytorch/pytorch/commit/10f16cc7daf89a73c1177dfbd0bb0fbb0fc8683b)
  - this one has failing internal tests, not related to a landrace with #138398 - reverting this one ([comment](https://github.com/pytorch/pytorch/pull/136526#issuecomment-2430460176))
- [Revert "Remove C10_DEPRECATED (#138406)"](https://github.com/pytorch/pytorch/commit/fc9093c3d2caaf2e79e01747bb24a83262ad246a)
  - failing internal tests - see D64714374 ([comment](https://github.com/pytorch/pytorch/pull/138406#issuecomment-2429912896))
- [Revert "[AOTI] Fix test_index_put_with_none_index_cpu_with_stack_allocation (#138303)"](https://github.com/pytorch/pytorch/commit/3b186c56596e2d89275135fc2c669cab288263af)
  - Diff reverted internally ([comment](https://github.com/pytorch/pytorch/pull/138303#issuecomment-2427991065))
- [Revert "[dynamo][NFC] Remove unused method `InliningInstructionTranslator.check_replace_is_safe` (#137906)"](https://github.com/pytorch/pytorch/commit/6987bfb40a8e70bf270a5382433ec6497e09be47)
  - There's nothing actually wrong with this PR, but something happened when importing that caused this to be landed out of order internally, resulting in a conflict with another PR ([comment](https://github.com/pytorch/pytorch/pull/137906#issuecomment-2425505452))

### Ignored Signal (3)

- [Revert "[aotd] Unwrap unseen AsyncCollectiveTensor tangents (#138731)"](https://github.com/pytorch/pytorch/commit/6f66398ab826706054ca4090ad82753287a067fd)
  - introduced regressions on linux-focal-cuda12.1-py3.10-gcc9-bazel-test ([comment](https://github.com/pytorch/pytorch/pull/138731#issuecomment-2438417669))
- [Revert "[BE]: Update Typeguard to TypeIs for better type inference (#133814)"](https://github.com/pytorch/pytorch/commit/32d4582e021241f3310dfe1bf010f424ba9f05f1)
  - checking if this will solve inductor errors ([comment](https://github.com/pytorch/pytorch/pull/133814#issuecomment-2427565425))
- [Revert "[AC] Backward Pass Aware AC - adding hooks to partitioner to pass callable (#137785)"](https://github.com/pytorch/pytorch/commit/9bb327bfc60c166ca15db1557c5d02ac28a161dc)
  - breaks lint ([comment](https://github.com/pytorch/pytorch/pull/137785#issuecomment-2427295668))

### No Signal (7)

- [Revert "In Inductor, be willing to generate deferred runtime asserts when unbacked (#138804)"](https://github.com/pytorch/pytorch/commit/d969b34377530cf600521c118c8093b3727d8536)
  - Sorry for reverting your change, but it seems to fail pr_time_benchmarks job in trunk ([comment](https://github.com/pytorch/pytorch/pull/138804#issuecomment-2440069407))
- [Revert "[fx graph cache] FxGraphPickler: Remove hack to stabilize device string hashes (#138681)"](https://github.com/pytorch/pytorch/commit/36b7135c6ff7ed1be4203968888ba4dd7ddbb3c6)
  - Introduced regressions on linux-focal-cuda11.8-py3.10-gcc9 ([comment](https://github.com/pytorch/pytorch/pull/138681#issuecomment-2438945493))
- [Revert "[c10d][CI] Improve world size setting in some tests (#138846)"](https://github.com/pytorch/pytorch/commit/447bb72822aacbb343c38c35fe4e97844f4e3919)
  - introduced breaks in linux-focal-cuda11.8-py3.10-gcc9 ([comment](https://github.com/pytorch/pytorch/pull/138846#issuecomment-2438415315))
- [Revert "[sparse] add search for optimal alg_id to torch.compile (#137427)"](https://github.com/pytorch/pytorch/commit/8197e4c70dcbfed01e2b0439b09f83ed0cbd9666)
  - this PR breaks AO tests ([comment](https://github.com/pytorch/pytorch/pull/137427#issuecomment-2435906592))
- [Revert "[PGNCCL] Use non-blocking mode by default in eager init (#138527)"](https://github.com/pytorch/pytorch/commit/cdfe1bffd16bdd28adbe5518038f68e6ac45de8d)
  - Seems to have introduce regressions on main, pull / linux-focal-cuda11.8-py3.10-gcc9 / test (distributed, 2, 3, linux.g4dn.12xlarge.nvidia.gpu) checking if revert will do ([comment](https://github.com/pytorch/pytorch/pull/138527#issuecomment-2432479338))
- [Revert "[Inductor] New Triton Attrs Descriptor Fixups (#138390)"](https://github.com/pytorch/pytorch/commit/9f7b987087a916eeb227767c1ab35aad42deada2)
  - Sorry for reverting your change, but it still has another lint error ([comment](https://github.com/pytorch/pytorch/pull/138390#issuecomment-2430566004))
- [Revert "[ROCm] Fix ADDMM hipBLASLt regression (#138267)"](https://github.com/pytorch/pytorch/commit/071f6f2de87c37611241f60bd1b1e7a338c72c21)
  - this PR went to far when partially reverting #137604; the env var default should be the same on ROCm and CUDA ([comment](https://github.com/pytorch/pytorch/pull/138267#issuecomment-2427550465))

### Weird (1)

- [Revert "[PGNCCL] Use non-blocking mode by default in eager init (#138527)"](https://github.com/pytorch/pytorch/commit/144d75d9341d1391bdd9c6158c1ad94223bb4365)
  - Sorry for reverting your change, but it is failing on ROCm ([comment](https://github.com/pytorch/pytorch/pull/138527#issuecomment-2440070035))
