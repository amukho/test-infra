# Week of 2024-10-14 to 2024-10-21 (34)

### GHFirst (14)

- [Revert "Fix unbind_copy and add its decomposition (#134319)"](https://github.com/pytorch/pytorch/commit/7b39fb57127f618a77b28fd39b569c4b3770146c)
  - breaking some executorch tests D64568664 ([comment](https://github.com/pytorch/pytorch/pull/134319#issuecomment-2423157700))
- [Revert "Dont decompose aten.baddmm in inductor (#137904)"](https://github.com/pytorch/pytorch/commit/af306a392cb84540b4798edea18cc5313a94e1ec)
  - unfortunately the failures on the previous import are still present on the current one D64568703 ([comment](https://github.com/pytorch/pytorch/pull/137904#issuecomment-2422789143))
- [Revert "[compiled autograd] directly use python Logger class in cpp (#137953)"](https://github.com/pytorch/pytorch/commit/66478d0cf7844cf966d90a5859d83eb425611f70)
  - breaking builds internally D64479322, I think it makes the build size of a package too large? The logs link to a wiki with instructions of what to do ([comment](https://github.com/pytorch/pytorch/pull/137953#issuecomment-2420086928))
- [Revert "Avoid some dangling reference warnings (#132535)"](https://github.com/pytorch/pytorch/commit/375dcb960f4fb0b46b7eeb9b0a147ffe37ab8919)
  - broke some internal builds D64479234 ([comment](https://github.com/pytorch/pytorch/pull/132535#issuecomment-2419983509))
- [Revert "Add decomposition for permute_copy (#130944)"](https://github.com/pytorch/pytorch/commit/4b3035f2feb4575c7d9eb9ab50f80bbe237c5ca1)
  - breaking internal builds D64418214 cc @digantdesai @GregoryComer to help get this fixed and remerged ([comment](https://github.com/pytorch/pytorch/pull/130944#issuecomment-2418125356))
- [Revert "Dont decompose aten.baddmm in inductor (#137904)"](https://github.com/pytorch/pytorch/commit/5254a0d383e486babe9c473ca83496faf0dfb065)
  - failing internal tests D64418200, some results not within tolerance? ([comment](https://github.com/pytorch/pytorch/pull/137904#issuecomment-2418122735))
- [Revert "Expose option to disable CRC-32 computation during `torch.save` (#137735)"](https://github.com/pytorch/pytorch/commit/dd32a32cb626529efbf87c5187e985e92421081c)
  - failing internally D64438525, probably needs gating ([comment](https://github.com/pytorch/pytorch/pull/137735#issuecomment-2417412264))
- [Revert "Make c10::string_view an alias of std::string_view (#130417)"](https://github.com/pytorch/pytorch/commit/cd292908e5d5f73a9a30f097c54f47c03e6fd42b)
  - breaking some internal tests, probably usages of string_view that need to be changed? ([comment](https://github.com/pytorch/pytorch/pull/130417#issuecomment-2414775064))
- [Revert "[ONNX] Remove ExportTypes (#137789)"](https://github.com/pytorch/pytorch/commit/60eb3fccfa603188e925a44bd2f2e1259e8b82db)
  - Diff reverted internally D64266727 Seems to be usages internally that need to be removed ([comment](https://github.com/pytorch/pytorch/pull/137789#issuecomment-2414632100))
- [Revert "[ONNX] Remove deprecated export_to_pretty_string (#137790)"](https://github.com/pytorch/pytorch/commit/2831af39c4e7e88105bc6f2fa6903b03e7009f8c)
  - Diff reverted internally D64266727 Seems to be usages internally that need to be removed ([comment](https://github.com/pytorch/pytorch/pull/137789#issuecomment-2414632100))
- [Revert "Add SVE implementation of embedding_lookup_idx (#133995)"](https://github.com/pytorch/pytorch/commit/dac0b4e62b865681b1171e043e244e65720a2c90)
  - breaking internal tests, I wondering if this just needs a targets change for buck? D64360590 ([comment](https://github.com/pytorch/pytorch/pull/133995#issuecomment-2414596554))
- [Revert "Make Context to be Device-agnostic Step by Step (1/N) (#136519)"](https://github.com/pytorch/pytorch/commit/d4d687ffb2cb8591c55de9d8bc8fabab9ced391c)
  - breaking internal tests related to MITA, @ezyang has a forward fix? ([comment](https://github.com/pytorch/pytorch/pull/136519#issuecomment-2414588302))
- [Revert "Make Context to be Device-agnostic Step by Step (2/N) (#136526)"](https://github.com/pytorch/pytorch/commit/9af4e0d2aacefc3fed8ab160a04ef0b847b0a51b)
  - breaking internal tests related to MITA, @ezyang has a forward fix? ([comment](https://github.com/pytorch/pytorch/pull/136519#issuecomment-2414588302))
- [Revert "cublaslt autotuning support for TunableOp (#133896)"](https://github.com/pytorch/pytorch/commit/3b7710316ca90b0264189606bc799249d46d4169)
  - this is breaking internal builds, I've copied what I think is the most relevant part of the log below. I believe the job running internally uses an old version of cuda, could you put guards to make sure compilation still words on an older version of cuda/cublaslt? ([comment](https://github.com/pytorch/pytorch/pull/133896#issuecomment-2412180893))

### Ignored Signal (1)

- [Revert "Update sympy version constraint to 1.13.3 (#138338)"](https://github.com/pytorch/pytorch/commit/d1027c2be6ad2ee8c9c50fa83293babd05cb6a2c)
  - Sorry for reverting your change, but I think a bunch of inductor tests and test_dynamic_shapes are failing in trunk after this lands https://hud.pytorch.org/pytorch/pytorch/commit/d8279ad9d162b5ce71699f462d3664c3745b14f5 ([comment](https://github.com/pytorch/pytorch/pull/138338#issuecomment-2424487225))

### Landrace (3)

- [Revert "[Traceable FSDP2] Add `_compiled_autograd_enabled` global state variable (#138187)"](https://github.com/pytorch/pytorch/commit/795255a7c8e23ae6d8315c38998e2d2f91bb0562)
  - linux-focal-rocm6.2-py3.10 / test (distributed, 1, 3, linux.rocm.gpu) test_compiled_autograd_ctx failed ([comment](https://github.com/pytorch/pytorch/pull/138187#issuecomment-2423609108))
- [Revert "[pt2] Log is_forward field to dynamo_compile scuba table (#138097)"](https://github.com/pytorch/pytorch/commit/47e40455669251282286ceadad2d30643f45963c)
  - Sorry for reverting your change, but I think it has a land race with https://github.com/pytorch/pytorch/pull/137803 ([comment](https://github.com/pytorch/pytorch/pull/138097#issuecomment-2423297516))
- [Revert "[Dynamo] Disable torch function compilation during guard execution and in compiled bytecode (#137669)"](https://github.com/pytorch/pytorch/commit/4557f6e339e7550b735067296ed479acc02e0487)
  - Sorry for reverting your change, but it is failing test_public_bindings in trunk, maybe a landrace ([comment](https://github.com/pytorch/pytorch/pull/137669#issuecomment-2415331274))

### Not through pytorchbot (1)

- [Revert "[Dynamo][autograd.Function] Trace fwd graph under no_grad mode (#134872)" (#137891)](https://github.com/pytorch/pytorch/commit/11e4232b4275150970236dbe7a220bd02eaf3d46)

### No Signal (8)

- [Revert "[Environment Variable][4/N] Use thread-safe getenv functions (#137843)"](https://github.com/pytorch/pytorch/commit/a1899b5a9eb335f1ec7afab1278f3ab666647e1c)
  - Sorry for reverting your PR but I believe this PR breaks the binary builds. Example: https://ossci-raw-job-status.s3.amazonaws.com/log/31790258895, with error message: `getenv is not a member of c10::utils`, might be easier to search for `not a member of` in the log ([comment](https://github.com/pytorch/pytorch/pull/137843#issuecomment-2425192780))
- [Revert "[inductor] Preserve metadata across replace_by_example and register_replacement patterns (#138089)"](https://github.com/pytorch/pytorch/commit/47e80abc7a9de6b5cdc20f7d1a8afb68c639d764)
  - Sorry for reverting your PR but the new test_original_aten_preserved_pad_mm test runs OOM in trunk https://hud.pytorch.org/pytorch/pytorch/commit/fb44658415e50b5be6a187ff3f14243c0fdf3daf ([comment](https://github.com/pytorch/pytorch/pull/138089#issuecomment-2424297269))
- [Revert "[inductor] add a threshold for membw saving during fusion (#136782)"](https://github.com/pytorch/pytorch/commit/ac7f52b301a6afddfc724836f09cef581ca20bb7)
  - Sorry for reverting your change but test_memory starts to fail after this lands in trunk ([comment](https://github.com/pytorch/pytorch/pull/136782#issuecomment-2423549196))
- [Revert "[user triton] typing triton_kernel_wrap.py (#138230)"](https://github.com/pytorch/pytorch/commit/e8b1409dcfbc7609110c9c332d6038a957b8dd9f)
  - Reverting this, as it started failing tests on main ([comment](https://github.com/pytorch/pytorch/pull/138230#issuecomment-2423354596))
- [Revert "Fix CompiledDDP failure when the gradient is not contiguous (#138174)"](https://github.com/pytorch/pytorch/commit/26ac5671dc4786ca6f3635d90e5f3b358c8b71df)
  - Sorry for reverting your PR, but I think it fails test_compute_comm_reordering in trunk for rocm and multigpu setup ([comment](https://github.com/pytorch/pytorch/pull/138174#issuecomment-2422818971))
- [Revert "[Distributed][CI] Add SM guard for compiled tests involving BF16 (#138245)"](https://github.com/pytorch/pytorch/commit/0ff6f7a04083d3fb7f4084cc16175d6cce6ff4b5)
  - Breaks distributed inductor tests ([comment](https://github.com/pytorch/pytorch/pull/138245#issuecomment-2422462579))
- [Revert "[CI] Add Compiled DDP and Compiled FSDP2 tests to test_inductor_distributed (#138178)"](https://github.com/pytorch/pytorch/commit/d2a6c732358db6dea9c4f4ddd3063081f140aa67)
  - Sorry for reverting your change, but the new tests are failing inductor distributed jobs ([comment](https://github.com/pytorch/pytorch/pull/138178#issuecomment-2420109501))
- [Revert "Fix autograd.Function + NJT when an output grad is None (#136875)"](https://github.com/pytorch/pytorch/commit/f8a5b7170a322225ddfd8fd505d9270f21c72193)
  - Caused memory leak ([comment](https://github.com/pytorch/pytorch/pull/136875#issuecomment-2411665776))

### Weird (7)

- [Revert "Enable git long paths checkout on Windows (#138411)"](https://github.com/pytorch/pytorch/commit/f8303740f78508c1dac94893bbc796dc080d6f0c)
  - Opps, I forgot Windows binary build, let me revert and reland this one ([comment](https://github.com/pytorch/pytorch/pull/138411#issuecomment-2424661640))
- [Revert "[CI] Add Compiled DDP and Compiled FSDP2 tests to test_inductor_distributed (#138178)"](https://github.com/pytorch/pytorch/commit/ada7a8c2178fb538ebd6a3610bba08958ffef156)
  - because https://github.com/pytorch/pytorch/pull/138174 is reverted, we need to revert this too ([comment](https://github.com/pytorch/pytorch/pull/138178#issuecomment-2422961292))
- [Revert "[Compiled Autograd] Check Dynamo stance to decide whether to fallback to eager (#138113)"](https://github.com/pytorch/pytorch/commit/3b0f3059f6008c06d9fe0b1192a7ffefcade5555)
  - sorry need to revert this in order to revert https://github.com/pytorch/pytorch/pull/137953, please rebase and remerge ([comment](https://github.com/pytorch/pytorch/pull/138113#issuecomment-2420079703))
- [Revert "Upgrade distributed test to g4dn instances (T4 GPUs) (#137161)"](https://github.com/pytorch/pytorch/commit/24ee4af86b081fb8bf7e7c2258d9748f62290542)
  - breaking trunk ([comment](https://github.com/pytorch/pytorch/pull/137161#issuecomment-2417833666))
- [Revert "[compiled autograd] Compiled autograd configs in TLS (#137821)"](https://github.com/pytorch/pytorch/commit/361f42bc42068e76b3721c7d71ac776df842f0d8)
  - Reverting this for now, it is failing test_public_bindings in trunk ([comment](https://github.com/pytorch/pytorch/pull/137821#issuecomment-2417351788))
- [Revert "Upgrade distributed test to g4dn instances (T4 GPUs) (#137161)"](https://github.com/pytorch/pytorch/commit/78632b97b134f6a647f129ee238031e7d4009203)
  - Sorry for reverting your change, but it seems another failure showing up after the upgrade ([comment](https://github.com/pytorch/pytorch/pull/137161#issuecomment-2415941159))
- [Revert "[Environment Variable][3/N] Use thread-safe getenv wrapper (#137328)"](https://github.com/pytorch/pytorch/commit/df0c2f5cae48a2e932bccf92cc4634fc942acbf1)
  - need to revert this in order to revert #133896, please rebase and reland, sorry for the churn ([comment](https://github.com/pytorch/pytorch/pull/137328#issuecomment-2412143739))
