# Week of 2025-03-10 to 2025-03-17 (17)

### GHFirst (10)

- [Revert "[pytree] add APIs to determine a class is a namedtuple or PyStructSequence (#113257)"](https://github.com/pytorch/pytorch/commit/f9b4856989c1bdd9c8c91278839ee7ee521bb0bb)
  - Sorry but this is breaking internally. @zou3519 can you please help land this internally? See the sigmoid tests in D71198793 for details. To validate the fixes internally, you can follow the instructions here: https://fburl.com/fixing-ghfirst-reverts ([comment](https://github.com/pytorch/pytorch/pull/113257#issuecomment-2725982539))
- [Revert "[RFC] First version of statically compiled launcher for triton compiled CUDA kernels (#148561)"](https://github.com/pytorch/pytorch/commit/643aaea1332eb78c08fc4c8249840f87f606dfb2)
  - Diff reverted internally ([comment](https://github.com/pytorch/pytorch/pull/148561#issuecomment-2725969268))
- [Revert "[AOTInductor] [BE] Add swap_constant_buffer into pybind for tests. (#149167)"](https://github.com/pytorch/pytorch/commit/71795f159e9f802acfad7235faf2939c2cf3e8d7)
  - Sorry but this is breaking internally. See D71177501 for the failure. To validate your fixes internally, you can follow the instructions here: https://fburl.com/fixing-ghfirst-reverts ([comment](https://github.com/pytorch/pytorch/pull/149167#issuecomment-2725001232))
- [Revert "[ROCm] Input vectorization in elementwise kernels for tensors with heterogeneous types (#147527)"](https://github.com/pytorch/pytorch/commit/e6839819c814d42fd4b5c9f110bc7828536a07a1)
  - Sorry but this is breaking internally.  @albanD, would you be able to help them land the fixes internally? The error looks really simple. See D71152448 for details. To validate the fixes internally, you can follow the instructions here: https://fburl.com/fixing-ghfirst-reverts ([comment](https://github.com/pytorch/pytorch/pull/147527#issuecomment-2723531085))
- [Revert "[Profiler][HPU] Fix incorrect availabilities for HPU (#148663)"](https://github.com/pytorch/pytorch/commit/e51615cb739c5c9b645501631c58b1188b7a7445)
  - Sorry but this is breaking internally. @albanD, could you please help get this relanded? See D71052806 for more details. To validate the fixes internally, you can follow the instructions here: https://fburl.com/fixing-ghfirst-reverts ([comment](https://github.com/pytorch/pytorch/pull/148663#issuecomment-2719297055))
- [Revert "Make dynamism code robust to NotImplementedException (#148823)"](https://github.com/pytorch/pytorch/commit/b1980b24059179b1b9b5f980aece82d7c7193e4a)
  - Sorry but this is breaking internally, see D71042206 for details. To validate your fixes internally before relanding, you can follow the instructions here: https://fburl.com/fixing-ghfirst-reverts ([comment](https://github.com/pytorch/pytorch/pull/148823#issuecomment-2719287467))
- [Revert "Reland: [inductor] Simplify grid handling (#148305)"](https://github.com/pytorch/pytorch/commit/5ada4e6a535f5a0cf53a87eae179f307376630e3)
  - Broke ROCm CI ([comment](https://github.com/pytorch/pytorch/pull/148305#issuecomment-2718177044))
- [Revert "Use the device interface for detecting Triton availability (#139171)"](https://github.com/pytorch/pytorch/commit/c916a8efc546fbbcc2fc2350fc6974a40dac73c8)
  - Sorry but this is breaking internally. @jansel can you please help get these changes working? See D70946254 for more details. To validate the fixes internally, you can follow the instructions here: https://fburl.com/fixing-ghfirst-reverts ([comment](https://github.com/pytorch/pytorch/pull/139171#issuecomment-2715392451))
- [Revert "[PGNCCL] Launch kernel on current stream & remove `record_stream` entirely (#148590)"](https://github.com/pytorch/pytorch/commit/a95eb0c0a7da160b2289c0f1febcb0a54f191f0f)
  - Breaking internally, see D70873275. Discussed reverting this with Ke. To validate your fixes internally, you can follow the instructions here: https://fburl.com/fixing-ghfirst-reverts ([comment](https://github.com/pytorch/pytorch/pull/148590#issuecomment-2712001270))
- [Revert "[pytree] add APIs to determine a class is a namedtuple or PyStructSequence (#113257)"](https://github.com/pytorch/pytorch/commit/ebd087e4b59248b83e0d54b3cbdbedb37d31e0b0)
  - breaking internal builds ([comment](https://github.com/pytorch/pytorch/pull/113257#issuecomment-2711299830))

### Ignored Signal (2)

- [Revert "Split up cub-RadixSortPairs.cu to parallelize compilation (#148936)"](https://github.com/pytorch/pytorch/commit/49570cb4024b167e4ed1baef49aad477279d3717)
  - Breaks lint in trunk [GH job link](https://github.com/pytorch/pytorch/actions/runs/13845459825/job/38742803351) [HUD commit link](https://hud.pytorch.org/pytorch/pytorch/commit/9a3d26cfcdb1c1be84a04baa3ee554dbe67cb049) ([comment](https://github.com/pytorch/pytorch/pull/148936#issuecomment-2722853628))
- [Revert "Refactor `test/test_torch.py` by moving testcase to `test_indexing.py` (#148875)"](https://github.com/pytorch/pytorch/commit/16560d4e8f8a33844d3bc629ecc6ff2c4c290a54)
  - That torch.version failure you got in CI was a legitimate failure and is now breaking trunk. [GH job link](https://github.com/pytorch/pytorch/actions/runs/13778023702/job/38534207536) [HUD commit link](https://hud.pytorch.org/pytorch/pytorch/commit/0fa0a740958ffc474843ceb1d19ee43c4bff4c09) ([comment](https://github.com/pytorch/pytorch/pull/148875#issuecomment-2714757288))

### No Signal (4)

- [Revert "[MPS] Add support for `i0e` in eager. (#149174)"](https://github.com/pytorch/pytorch/commit/be4e6c1c8ee79bdc26f693c353dca4379e3930a8)
  - MPS are red on trunk ([comment](https://github.com/pytorch/pytorch/pull/149174#issuecomment-2723774600))
- [Revert "[CI] Don't clean workspace when fetching repo (#147994)"](https://github.com/pytorch/pytorch/commit/626a5e22eb158e14746aeb27d407a946bf0586e5)
  - broke checkout on xpu, probably lack of sudo? ([comment](https://github.com/pytorch/pytorch/pull/147994#issuecomment-2718335186))
- [Revert "[logging] Set compile_id in the CachingAutotuner during compilation so we have it for dynamo_timed logging (#148693)"](https://github.com/pytorch/pytorch/commit/b54cf1a2814dc8e0d68738add86f0c41bd7f2e75)
  - This is breaking lint on trunk. Please rebase these changes before merging them back in. [GH job link](https://github.com/pytorch/pytorch/actions/runs/13796723235/job/38590020554) [HUD commit link](https://hud.pytorch.org/pytorch/pytorch/commit/73c8068cf889829fb811fc75baac03163c9a42ee) ([comment](https://github.com/pytorch/pytorch/pull/148693#issuecomment-2715671875))
- [Revert "[WIP] Initial implementation of Grouped Gemm API (#148531)"](https://github.com/pytorch/pytorch/commit/c983e1124cd83ad31f856014110dd436beabc324)
  - Sorry but this broke ROCm jobs on trunk ([comment](https://github.com/pytorch/pytorch/pull/148531#issuecomment-2714577498))

### Weird (1)

- [Revert "Move aoti_torch_cpu__weight_int4pack_mm_cpu_tensor to not be mangled (#148834)"](https://github.com/pytorch/pytorch/commit/2ec9aceaeb77176c4bdeb2d008a34cba0cd57e3c)
  - sorry I don't think I want this PR in before the branch cut, as it'd freeze the API in the file when it should really be in a different header ([comment](https://github.com/pytorch/pytorch/pull/148834#issuecomment-2711162193))
