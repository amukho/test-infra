# Week of 2024-12-16 to 2024-12-23 (23)

### GHFirst (10)

- [Revert "export AOTI_TORCH_EXPORT on Windows. (#140030)"](https://github.com/pytorch/pytorch/commit/e15442a9b279505408cbb170d9ae1521b1492080)
  - Sorry for reverting your change, but my first attempt to fix internal build does not fix all the cases, so let us try again ([comment](https://github.com/pytorch/pytorch/pull/140030#issuecomment-2558043056))
- [Revert "[pytorch/et] Allow ET to save additional resources for completing a trace like generated kernels and index tensor data (#143430)"](https://github.com/pytorch/pytorch/commit/bee47b0663aeb210aa5cad6c952147c79a470481)
  - The internal diff D58707846 has been backed out ([comment](https://github.com/pytorch/pytorch/pull/143430#issuecomment-2558033930))
- [Revert "[MTIA] (3/n) Implement PyTorch APIs to query/reset device peak memory usage (#143347)"](https://github.com/pytorch/pytorch/commit/c7d7eff798e375d1ff886932f657dc52bb4336ab)
  - D67118173 has been backed out internally ([comment](https://github.com/pytorch/pytorch/pull/143347#issuecomment-2557983266))
- [Revert "(MTIA) Move "empty_cache" API (#143402)"](https://github.com/pytorch/pytorch/commit/dabc9566c497e49d973aae60260171b6eaaa922a)
  - The internal diff D67148738 has been reverted ([comment](https://github.com/pytorch/pytorch/pull/143402#issuecomment-2557982597))
- [Revert "[Inductor] inplace padding (#140249)"](https://github.com/pytorch/pytorch/commit/4462cc6375f7e0c2289e8457e5ab377b749d6411)
  - This break an internal test https://fburl.com/test/ppl2we5l ([comment](https://github.com/pytorch/pytorch/pull/140249#issuecomment-2556079406))
- [Revert "[ARM][feat]: Add 4 bit dynamic quantization matmuls & KleidiAI Backend (#134124)"](https://github.com/pytorch/pytorch/commit/8136daff5a1f823212166e712dc3362750937dd4)
  - Sorry for reverting your change but it breaks lots of internal build ([comment](https://github.com/pytorch/pytorch/pull/134124#issuecomment-2555953189))
- [Revert "[Dynamo] only import einops if version is lower than 0.7.0 (#142847)"](https://github.com/pytorch/pytorch/commit/145fd5bad0cd16141fc0004d96c6c52f9759e09f)
  - This has been reverted internally D67436053 ([comment](https://github.com/pytorch/pytorch/pull/142847#issuecomment-2555942351))
- [Revert "[export] don't decompose custom triton op when exporting (#142426)"](https://github.com/pytorch/pytorch/commit/e9bd74d7636376b8775cbfee96ae5fa34d496e6f)
  - This fails one internal MTIA test, checking with the author that we need to revert and reland this ([comment](https://github.com/pytorch/pytorch/pull/142426#issuecomment-2555793496))
- [Revert "[reland][dynamo][guards] Consider tensors as immutable for dict tag matches (#141085)"](https://github.com/pytorch/pytorch/commit/e3d754419f73bfce4a50be27ba01e053e08b5e11)
  - The diff D66211131 has been commandeered internally and is it not part of the train anymore.  If codev is needed, pls reland this accordingly ([comment](https://github.com/pytorch/pytorch/pull/141085#issuecomment-2549092225))
- [Revert "Update low prec codegen for div/mod (#142350)"](https://github.com/pytorch/pytorch/commit/54ed13cdce08de00d411d615fb72a73773dba2c3)
  - Sorry for reverting your change but I think it. breaks an internal test ([comment](https://github.com/pytorch/pytorch/pull/142350#issuecomment-2546615951))

### Ignored Signal (4)

- [Revert "Handle meta tensors in FX quantization (#142262)"](https://github.com/pytorch/pytorch/commit/197954e14b229d7422a0a4f58958f38455916083)
  - this PR broke lint  ([comment](https://github.com/pytorch/pytorch/pull/142262#issuecomment-2558233022))
- [Revert "Fix unused-variable issues in caffe2 (#143639)"](https://github.com/pytorch/pytorch/commit/97990f476d4746b3067008a0f81a48d63c205606)
  - This is failing OSS tests ([comment](https://github.com/pytorch/pytorch/pull/143639#issuecomment-2557991297))
- [Revert "[logging] A few fixes/updates to record_compilation_metrics (#143332)"](https://github.com/pytorch/pytorch/commit/ad7ab5ef8401a15e32e84b913fa04457571e81df)
  - Surprisingly failure is caused by this PR ([comment](https://github.com/pytorch/pytorch/pull/143332#issuecomment-2557899120))
- [Revert "Kill capture_pre_autograd_graph API (#143224)"](https://github.com/pytorch/pytorch/commit/519d858c31a9079bd93d6ab610bbe8c1e835f4e4)
  - Sorry for reverting your change but the XLA failure is legit ([comment](https://github.com/pytorch/pytorch/pull/143224#issuecomment-2547264675))

### Landrace (1)

- [Revert "FileTimerClient: add retry logic on connect (#143318)"](https://github.com/pytorch/pytorch/commit/533d63f83b413cfa6226de1cccb55f9ad6a7e155)
  - Sorry for reverting your change but it is failing lint jobs in trunk ([comment](https://github.com/pytorch/pytorch/pull/143318#issuecomment-2547342910))

### Not through pytorchbot (2)

- [Revert "refactor tensorify restart logic to use sources (#141517)" (#143623)](https://github.com/pytorch/pytorch/commit/4f8b7c4272db521f7ffc4070ce1bdece513d1183)
- [Back out "Fix undesired specialization on slice after split. (#142372)" (#143356)](https://github.com/pytorch/pytorch/commit/c3f3a6e4d25ba369cc9237b0797afe38917d7c6d)

### No Signal (4)

- [Revert "[AOTI] Emit a CMakeLists.txt when package_cpp_only (#143352)"](https://github.com/pytorch/pytorch/commit/71479a9b9c6a082487bc1d26a3aea14f5dd06116)
  - Sorry for reverting your change but the new test is failing on ROCm ([comment](https://github.com/pytorch/pytorch/pull/143352#issuecomment-2556365140))
- [Revert "[ARM][feat]: Add 4 bit dynamic quantization matmuls & KleidiAI Backend (#134124)"](https://github.com/pytorch/pytorch/commit/14fe1f719026af1e6d0020c5ab1c85a5048e2eba)
  - This broke S390 builds, includes cpuinfo unconditionally ([comment](https://github.com/pytorch/pytorch/pull/134124#issuecomment-2552560208))
- [Revert "[BE] Revert "Add conda to Manylinux Docker images (#139903)" (#143300)"](https://github.com/pytorch/pytorch/commit/6356690b3d283c65d5f990af911614cbb50b68be)
  - failing nova workflows with conda: command not found ([comment](https://github.com/pytorch/pytorch/pull/143300#issuecomment-2547030664))
- [Revert "[AMD] Turn on TF32 for aten::mm (#139869)"](https://github.com/pytorch/pytorch/commit/7ab3177776a9752c31cb424281943e859dd6a305)
  - causing ROCm CI failures, need to investigate, revert for now ([comment](https://github.com/pytorch/pytorch/pull/139869#issuecomment-2546127069))

### Weird (2)

- [Revert "Fix issue with setAttribute and int8_t vs int32_t variables (#143693)"](https://github.com/pytorch/pytorch/commit/b89bfe0bacb37b4fbce205b2335fd72b7a5d1b59)
  - Sorry for reverting this change but it has a conflict with https://github.com/pytorch/pytorch/pull/143639 that is breaking trunk ([comment](https://github.com/pytorch/pytorch/pull/143693#issuecomment-2557990508))
- [Revert "[ROCm] CK Flash Attention Backend (#138947)"](https://github.com/pytorch/pytorch/commit/969b07b96f490c6ebcb3154dcc0e3ce27f0aa0bc)
  - Breaks default windows checkout ([comment](https://github.com/pytorch/pytorch/pull/138947#issuecomment-2548998359))
